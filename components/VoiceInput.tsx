'use client';

import { useCallback, useEffect, useRef, useState } from 'react';
import styles from './VoiceInput.module.css';

export interface CustomWord {
    reading: string; // èª­ã¿ä»®åï¼ˆéŸ³å£°èªè­˜ã§å‡ºã¦ãã‚‹è¡¨è¨˜ï¼‰
    word: string;    // æ­£ã—ã„è¡¨è¨˜ï¼ˆè£½å“åãƒ»å‹ç•ªãªã©ï¼‰
}

interface VoiceInputProps {
    onTranscript: (text: string) => void;
    isLoading: boolean;
    customWords?: CustomWord[];
    onAutoSubmitPrompt?: (text: string) => void; // 30ç§’å¾Œã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
}

// ã‚«ã‚¹ã‚¿ãƒ å˜èªã§ç½®æ›è£œæ­£ã™ã‚‹
function applyCustomWords(text: string, customWords: CustomWord[]): string {
    let result = text;
    for (const { reading, word } of customWords) {
        if (!reading || !word) continue;
        // å¤§æ–‡å­—å°æ–‡å­—ãƒ»ã²ã‚‰ãŒãª/ã‚«ã‚¿ã‚«ãƒŠã‚’è€ƒæ…®ã—ãŸç°¡æ˜“ç½®æ›
        result = result.replaceAll(reading, word);
    }
    return result;
}

export default function VoiceInput({ onTranscript, isLoading, customWords = [], onAutoSubmitPrompt }: VoiceInputProps) {
    const [isListening, setIsListening] = useState(false);
    const [transcript, setTranscript] = useState('');
    const [isSupported, setIsSupported] = useState(false);
    const [autoSubmitCountdown, setAutoSubmitCountdown] = useState<number | null>(null);

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const recognitionRef = useRef<any>(null);
    const canvasRef = useRef<HTMLCanvasElement>(null);
    const animFrameRef = useRef<number>(0);
    const audioContextRef = useRef<AudioContext | null>(null);
    const analyserRef = useRef<AnalyserNode | null>(null);
    const micStreamRef = useRef<MediaStream | null>(null);

    // æ©Ÿèƒ½4: ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆã‚’è“„ç©ã™ã‚‹Refï¼ˆonresultã®ãŸã³ã«ãƒªã‚»ãƒƒãƒˆã—ãªã„ï¼‰
    const accumulatedFinalRef = useRef<string>('');
    // æ©Ÿèƒ½5: 30ç§’ã‚¿ã‚¤ãƒãƒ¼
    const autoSubmitTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
    const countdownIntervalRef = useRef<ReturnType<typeof setInterval> | null>(null);
    // ã‚«ã‚¹ã‚¿ãƒ å˜èªã®æœ€æ–°å€¤ã‚’Refã§ä¿æŒ
    const customWordsRef = useRef<CustomWord[]>(customWords);
    useEffect(() => { customWordsRef.current = customWords; }, [customWords]);

    // 30ç§’ã‚¿ã‚¤ãƒãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆãƒ»èµ·å‹•
    const resetAutoSubmitTimer = useCallback((currentText: string) => {
        if (autoSubmitTimerRef.current) clearTimeout(autoSubmitTimerRef.current);
        if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current);

        if (!currentText.trim()) {
            setAutoSubmitCountdown(null);
            return;
        }

        // ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³è¡¨ç¤º
        setAutoSubmitCountdown(30);
        countdownIntervalRef.current = setInterval(() => {
            setAutoSubmitCountdown((prev) => {
                if (prev === null || prev <= 1) {
                    if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current);
                    return null;
                }
                return prev - 1;
            });
        }, 1000);

        autoSubmitTimerRef.current = setTimeout(() => {
            setAutoSubmitCountdown(null);
            if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current);
            if (onAutoSubmitPrompt) {
                onAutoSubmitPrompt(accumulatedFinalRef.current);
            }
        }, 30000);
    }, [onAutoSubmitPrompt]);

    // ã‚¿ã‚¤ãƒãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    const cancelAutoSubmitTimer = useCallback(() => {
        if (autoSubmitTimerRef.current) clearTimeout(autoSubmitTimerRef.current);
        if (countdownIntervalRef.current) clearInterval(countdownIntervalRef.current);
        setAutoSubmitCountdown(null);
    }, []);

    useEffect(() => {
        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
        setIsSupported(!!SpeechRecognition);

        if (SpeechRecognition) {
            const recognition = new SpeechRecognition();
            recognition.lang = 'ja-JP';
            recognition.continuous = true;
            recognition.interimResults = true;

            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            recognition.onresult = (event: any) => {
                let newFinalText = '';
                let interimText = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    if (event.results[i].isFinal) {
                        // ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆã‚’è£œæ­£ã—ã¦ã‹ã‚‰è¿½è¨˜
                        const corrected = applyCustomWords(event.results[i][0].transcript, customWordsRef.current);
                        newFinalText += corrected;
                    } else {
                        interimText += event.results[i][0].transcript;
                    }
                }

                // æ©Ÿèƒ½4: ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆã‚’è“„ç©ï¼ˆä¸Šæ›¸ãã§ã¯ãªãè¿½è¨˜ï¼‰
                if (newFinalText) {
                    accumulatedFinalRef.current += newFinalText;
                    // æ©Ÿèƒ½5: ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆãŒè¿½åŠ ã•ã‚ŒãŸã‚‰ã‚¿ã‚¤ãƒãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
                    resetAutoSubmitTimer(accumulatedFinalRef.current);
                }

                const displayText = accumulatedFinalRef.current + interimText;
                setTranscript(displayText);
            };

            recognition.onend = () => {
                // continuous=trueã§ã‚‚ç«¯æœ«ã«ã‚ˆã£ã¦ã¯æ­¢ã¾ã‚‹ã“ã¨ãŒã‚ã‚‹ â†’ è‡ªå‹•å†èµ·å‹•
                if (isListeningRef.current) {
                    try { recognition.start(); } catch { /* ignore */ }
                } else {
                    setIsListening(false);
                    stopVisualizer();
                }
            };

            recognitionRef.current = recognition;
        }

        return () => {
            stopVisualizer();
            cancelAutoSubmitTimer();
        };
        // eslint-disable-next-line react-hooks/exhaustive-deps
    }, []);

    // isListeningã‚’Refã§ã‚‚ä¿æŒï¼ˆonend ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£å†…ã§å‚ç…§ã™ã‚‹ãŸã‚ï¼‰
    const isListeningRef = useRef(false);
    useEffect(() => { isListeningRef.current = isListening; }, [isListening]);

    const drawVisualizer = () => {
        const canvas = canvasRef.current;
        const analyser = analyserRef.current;
        if (!canvas || !analyser) return;
        const ctx = canvas.getContext('2d');
        if (!ctx) return;

        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        const draw = () => {
            animFrameRef.current = requestAnimationFrame(draw);
            analyser.getByteFrequencyData(dataArray);
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            const barWidth = (canvas.width / bufferLength) * 2.5;
            let x = 0;
            for (let i = 0; i < bufferLength; i++) {
                const barHeight = (dataArray[i] / 255) * canvas.height;
                const gradient = ctx.createLinearGradient(0, canvas.height - barHeight, 0, canvas.height);
                gradient.addColorStop(0, 'rgba(99, 207, 197, 0.9)');
                gradient.addColorStop(1, 'rgba(59, 130, 246, 0.5)');
                ctx.fillStyle = gradient;
                ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                x += barWidth + 1;
            }
        };
        draw();
    };

    const startVisualizer = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            micStreamRef.current = stream;
            const audioContext = new AudioContext();
            audioContextRef.current = audioContext;
            const analyser = audioContext.createAnalyser();
            analyser.fftSize = 128;
            analyserRef.current = analyser;
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);
            drawVisualizer();
        } catch {
            console.warn('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ');
        }
    };

    const stopVisualizer = () => {
        if (animFrameRef.current) cancelAnimationFrame(animFrameRef.current);
        if (micStreamRef.current) {
            micStreamRef.current.getTracks().forEach((t) => t.stop());
            micStreamRef.current = null;
        }
        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }
    };

    const toggleListening = () => {
        if (!recognitionRef.current) return;

        if (isListening) {
            // åœæ­¢ï¼šè“„ç©ãƒ†ã‚­ã‚¹ãƒˆã¯ãã®ã¾ã¾æ®‹ã™ï¼ˆè¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ï¼‰
            recognitionRef.current.stop();
            stopVisualizer();
            setIsListening(false);
        } else {
            // é–‹å§‹ï¼šè“„ç©ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦æ–°è¦éŒ²éŸ³
            accumulatedFinalRef.current = '';
            setTranscript('');
            cancelAutoSubmitTimer();
            recognitionRef.current.start();
            startVisualizer();
            setIsListening(true);
        }
    };

    const handleSubmit = useCallback(() => {
        const text = transcript.trim();
        if (text) {
            cancelAutoSubmitTimer();
            onTranscript(text);
            // é€ä¿¡å¾Œãƒªã‚»ãƒƒãƒˆ
            accumulatedFinalRef.current = '';
            setTranscript('');
            if (isListening) {
                recognitionRef.current?.stop();
                stopVisualizer();
                setIsListening(false);
            }
        }
        // eslint-disable-next-line react-hooks/exhaustive-deps
    }, [transcript, isListening, onTranscript, cancelAutoSubmitTimer]);

    if (!isSupported) {
        return (
            <div className={styles.unsupported}>
                âš ï¸ ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°èªè­˜ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚Chrome ã‚’ãŠä½¿ã„ãã ã•ã„ã€‚
            </div>
        );
    }

    return (
        <div className={styles.container}>
            <canvas ref={canvasRef} className={styles.canvas} width={500} height={60} />

            {/* 30ç§’ã‚«ã‚¦ãƒ³ãƒˆãƒ€ã‚¦ãƒ³è¡¨ç¤º */}
            {autoSubmitCountdown !== null && (
                <div className={styles.countdownBar}>
                    <span className={styles.countdownIcon}>â±</span>
                    <span>{autoSubmitCountdown}ç§’å¾Œã«é€ä¿¡ç¢ºèªã—ã¾ã™</span>
                    <button className={styles.countdownCancel} onClick={cancelAutoSubmitTimer}>
                        ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                    </button>
                </div>
            )}

            <div className={styles.inputRow}>
                <textarea
                    className={styles.textarea}
                    value={transcript}
                    onChange={(e) => {
                        setTranscript(e.target.value);
                        accumulatedFinalRef.current = e.target.value;
                    }}
                    placeholder={isListening ? 'ğŸ™ è©±ã—ã‹ã‘ã¦ãã ã•ã„... (é–“ãŒç©ºã„ã¦ã‚‚è¿½è¨˜ã•ã‚Œã¾ã™)' : 'ã“ã“ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã‹ã€ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„'}
                    rows={3}
                />
                <div className={styles.buttons}>
                    <button
                        className={`${styles.micBtn} ${isListening ? styles.active : ''}`}
                        onClick={toggleListening}
                        title={isListening ? 'åœæ­¢ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¯æ®‹ã‚Šã¾ã™ï¼‰' : 'éŸ³å£°å…¥åŠ›é–‹å§‹'}
                    >
                        {isListening ? 'â¹' : 'ğŸ™'}
                    </button>
                    <button
                        className={styles.sendBtn}
                        onClick={handleSubmit}
                        disabled={!transcript.trim() || isLoading}
                    >
                        é€ä¿¡
                    </button>
                </div>
            </div>
        </div>
    );
}
